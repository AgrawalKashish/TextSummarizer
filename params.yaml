# TrainingArguments:
#   num_train_epochs: 1
#   warmup_steps: 500
#   per_device_train_batch_size: 1
#   weight_decay: 0.01
#   logging_steps: 10
#   evaluation_strategy: steps
#   eval_steps: 500
#   save_steps: 1e6
#   gradient_accumulation_steps: 16

TrainingArguments:
    num_train_epochs: 1
    warmup_steps: 200
    per_device_train_batch_size: 4 # Adjust based on your GPU capacity
    per_device_eval_batch_size: 4
    weight_decay: 0.01
    logging_steps: 50  # Adjust to reduce logging frequency
    evaluation_strategy: "epoch"  # Evaluate at the end of each epoch
    save_steps: 5000  # Save model less frequently
    gradient_accumulation_steps: 4  # Lower accumulation for faster updates
